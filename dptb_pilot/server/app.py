import asyncio
import json
import os
import uuid
import copy
from typing import Dict, List, Optional, Any, AsyncGenerator
from pathlib import Path
from datetime import datetime

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, FileResponse
from pydantic import BaseModel
import uvicorn

from dptb_pilot.core.agent import create_llm_agent
from dptb_pilot.core.session import pop_event
from dptb_pilot.core.guardrail import zip_tool_schema, extract_arguments_from_schema
from dptb_pilot.core.utils import generate_random_string, hash_dict
from dptb_pilot.tools.loader import get_mcp_server_tools # Note: loader doesn't exist yet, need to create or fix path
from google.adk.agents import LlmAgent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types
from dptb_pilot.core.logger import get_logger
from dptb_pilot.core.photon_service import get_photon_service, PhotonChargeResult
from dptb_pilot.core.photon_config import CHARGING_ENABLED

logger = get_logger(__name__)


# å…¨å±€çŠ¶æ€ç®¡ç† (ä¿æŒä¸åŸmain.pyå…¼å®¹)
active_agents: Dict[str, LlmAgent] = {}
history_pool: Dict[str, List[List[str]]] = {}
session_service = InMemorySessionService()

# MCPå·¥å…·æ‹¦æˆªç›¸å…³çŠ¶æ€
pending_events: Dict[str, asyncio.Event] = {}
unmodified_schema_store: Dict[str, Dict] = {}
modified_schema_store: Dict[str, Dict] = {}
modified_args_store: Dict[str, Dict] = {}

# ç»ˆæ­¢æ‰§è¡Œç›¸å…³çŠ¶æ€
cancel_execution_events: Dict[str, asyncio.Event] = {}
termination_requested: Dict[str, bool] = {}

# é…ç½®ä¿¡æ¯
target_tools: List[str] = []
tools_info: List[Dict[str, Any]] = {}
agent_info: Dict[str, Any] = {}
model_config: Dict[str, Any] = {}
mcp_server_url: str = ""
work_path: str = "/tmp"

# FastAPIåº”ç”¨
app = FastAPI(title="Better AIM React API", version="1.0.0")

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    expose_headers=["*"]
)

# WebSocketè¿æ¥ç®¡ç†
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, websocket: WebSocket, session_id: str):
        await websocket.accept()
        self.active_connections[session_id] = websocket

    def disconnect(self, session_id: str):
        if session_id in self.active_connections:
            del self.active_connections[session_id]

    async def send_message(self, session_id: str, message: dict):
        if session_id in self.active_connections:
            await self.active_connections[session_id].send_text(json.dumps(message))

manager = ConnectionManager()


# Pydanticæ¨¡å‹
class LoginRequest(BaseModel):
    session_id: str

class ChatMessage(BaseModel):
    message: str
    session_id: str
    chat_id: Optional[str] = None

class ModifyParamsRequest(BaseModel):
    session_id: str
    modified_schema: Dict[str, Any]
    execution_mode: str = 'Local'
    selected_machine_id: Optional[str] = None
    remote_machine: Optional[Dict[str, Any]] = None  # åŒ…å«å®Œæ•´çš„è¿œç¨‹æœºå™¨é…ç½®

class TerminateExecutionRequest(BaseModel):
    session_id: str


def generate_executor_and_storage(
    execution_mode: str,
    remote_machine: Optional[Dict[str, Any]],
    tool_schema: Dict[str, Any]
) -> Dict[str, Any]:
    """
    æ ¹æ®æ‰§è¡Œæ¨¡å¼å’Œè¿œç¨‹æœºå™¨é…ç½®è‡ªåŠ¨ç”Ÿæˆ Executor å’Œ Storage å‚æ•°

    Args:
        execution_mode: æ‰§è¡Œæ¨¡å¼ ('Local' æˆ– 'Remote')
        remote_machine: è¿œç¨‹æœºå™¨é…ç½®
        tool_schema: å·¥å…· schema

    Returns:
        æ›´æ–°åçš„å·¥å…· schemaï¼ŒåŒ…å«è‡ªåŠ¨ç”Ÿæˆçš„ Executor å’Œ Storage å‚æ•°
    """
    if execution_mode != 'Remote' or not remote_machine:
        return tool_schema

    machine_type = remote_machine.get('type')
    config = remote_machine.get('config', {})

    if not machine_type or not config:
        logger.warning(f"[AutoGenerate] æ— æ•ˆçš„è¿œç¨‹æœºå™¨é…ç½®: {remote_machine}")
        return tool_schema

    logger.info("=" * 80)
    logger.info(f"[AutoGenerate] å¼€å§‹è‡ªåŠ¨ç”Ÿæˆ Executor å’Œ Storage å‚æ•°")
    logger.info(f"[AutoGenerate] æœºå™¨ç±»å‹: {machine_type}")
    logger.info(f"[AutoGenerate] æœºå™¨é…ç½®: {json.dumps(config, ensure_ascii=False, indent=2)}")

    # æ·±æ‹·è´ tool_schema é¿å…ä¿®æ”¹åŸå¯¹è±¡
    result_schema = copy.deepcopy(tool_schema)

    # æ›´æ–° schema ä¸­çš„ Executor å’Œ Storage å‚æ•°
    properties = result_schema.get('input_schema', {}).get('properties', {})

    # ç”Ÿæˆ Executor é…ç½®ï¼ˆæ”¯æŒå¤§å†™å’Œå°å†™çš„ keyï¼‰
    executor_key = None
    for key in ['Executor', 'executor']:
        if key in properties:
            executor_key = key
            break

    if executor_key:
        if machine_type == 'Bohrium':
            executor_config = {
                'type': 'dispatcher',
                'machine': {
                    'batch_type': 'Bohrium',
                    'context_type': 'Bohrium',
                    'remote_profile': {
                        'email': config.get('username'),
                        'password': config.get('password'),
                        'program_id': int(config.get('project_id', 0)),
                        'input_data': {
                            'image_name': config.get('image_name') or 'registry.dp.tech/dptech/dp/native/prod-35271/dptb-pilot-test:0.2',
                            'job_type': 'container',
                            'platform': 'ali',
                            'scass_type': config.get('scass_type') or 'c2_m4_cpu'
                        }
                    }
                }
            }
            logger.info(f"[AutoGenerate] Bohrium Executor é…ç½®å·²ç”Ÿæˆ")
            logger.info(f"[AutoGenerate] Executor: {json.dumps(executor_config, ensure_ascii=False, indent=2)}")
            properties[executor_key]['user_input'] = executor_config

        elif machine_type == 'Slurm':
            executor_config = {
                'type': 'dispatcher',
                'machine': {
                    'batch_type': 'Slurm',
                    'context_type': 'SSHContext',
                    'local_root': './',
                    'remote_root': config.get('remote_root'),
                    'remote_profile': {
                        'hostname': config.get('hostname'),
                        'username': config.get('username'),
                        'timeout': 600,
                        'port': 22,
                        'key_filename': config.get('key_filename')
                    }
                },
                'resources': {
                    'number_node': int(config.get('number_node', 1)),
                    'gpu_per_node': int(config.get('gpu_per_node', 0)) if config.get('gpu_per_node') else 0,
                    'cpu_per_node': int(config.get('cpu_per_node', 1)) if config.get('cpu_per_node') else 1,
                    'queue_name': config.get('queue_name'),
                    'custom_flags': [config.get('custom_flags', ''), ''],
                    'source_list': [],
                    'module_list': []
                }
            }
            logger.info(f"[AutoGenerate] Slurm Executor é…ç½®å·²ç”Ÿæˆ")
            logger.info(f"[AutoGenerate] Executor: {json.dumps(executor_config, ensure_ascii=False, indent=2)}")
            properties[executor_key]['user_input'] = executor_config

    # ç”Ÿæˆ Storage é…ç½®ï¼ˆä»… Bohrium ç±»å‹ï¼‰
    storage_key = None
    for key in ['Storage', 'storage']:
        if key in properties:
            storage_key = key
            break

    if storage_key and machine_type == 'Bohrium':
        storage_config = {
            'type': 'bohrium',
            'username': config.get('username'),
            'password': config.get('password'),
            'project_id': int(config.get('project_id', 0))
        }
        logger.info(f"[AutoGenerate] Bohrium Storage é…ç½®å·²ç”Ÿæˆ")
        logger.info(f"[AutoGenerate] Storage: {json.dumps(storage_config, ensure_ascii=False, indent=2)}")
        properties[storage_key]['user_input'] = storage_config

    logger.info(f"[AutoGenerate] å®Œæˆ Executor å’Œ Storage å‚æ•°è‡ªåŠ¨ç”Ÿæˆ")
    logger.info("=" * 80)

    return result_schema

async def call_agent_async(query: str, runner: Runner, user_id: str, session_id: str) -> AsyncGenerator[Dict[str, Any], None]:
    """ä¸agentå¼‚æ­¥å¯¹è¯ï¼Œæ”¯æŒMCPå·¥å…·æ‹¦æˆª"""
    content = types.Content(role='user', parts=[types.Part(text=query)])

    async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):
        # æ£€æŸ¥æ˜¯å¦è¢«ç»ˆæ­¢
        if termination_requested.get(session_id, False):
            logger.info(f"[CallAgent] ä¼šè¯ {session_id} å·²è¯·æ±‚ç»ˆæ­¢")
            yield {
                "type": "final_response",
                "content": "æ‰§è¡Œå·²ç»ˆæ­¢",
                "is_final": True
            }
            # æ¸…ç†ç»ˆæ­¢çŠ¶æ€
            termination_requested[session_id] = False
            if session_id in pending_events:
                pending_events[session_id].set()
            break

        # å¤„ç†å·¥å…·è°ƒç”¨
        if event.content and event.content.parts:
            calls = event.get_function_calls()
            if calls:
                for call in calls:
                    tool_name = call.name
                    arguments = call.args

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‹¦æˆª
                    if tool_name in target_tools:
                        schema = zip_tool_schema(
                            tool_name=tool_name,
                            arguments=arguments,
                            tools_dict=tools_info
                        )

                        # å­˜å‚¨schemaå¹¶ç­‰å¾…ç”¨æˆ·ä¿®æ”¹
                        unmodified_schema_store[session_id] = schema
                        pending_events[session_id] = asyncio.Event()

                        # é€šçŸ¥å‰ç«¯éœ€è¦ä¿®æ”¹å‚æ•°
                        await manager.send_message(session_id, {
                            "type": "tool_modify_required",
                            "schema": schema,
                            "tool_name": tool_name
                        })

                        # ç­‰å¾…ç”¨æˆ·ä¿®æ”¹å®Œæˆæˆ–ç»ˆæ­¢
                        # åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥æ£€æŸ¥å–æ¶ˆäº‹ä»¶
                        cancel_task = None
                        if session_id in cancel_execution_events:
                            cancel_execution_events[session_id] = asyncio.Event()
                            cancel_task = asyncio.create_task(cancel_execution_events[session_id].wait())

                        # ç­‰å¾… pending_event æˆ– cancel_event
                        try:
                            await asyncio.wait_for(pending_events[session_id].wait(), timeout=600.0)
                        except asyncio.TimeoutError:
                            logger.warning(f"[CallAgent] ä¼šè¯ {session_id} ç­‰å¾…å‚æ•°ä¿®æ”¹è¶…æ—¶")
                            break

                        # æ¸…ç† cancel_task
                        if cancel_task:
                            cancel_task.cancel()
                        if session_id in cancel_execution_events:
                            cancel_execution_events[session_id] = None

                        # æ£€æŸ¥æ˜¯å¦è¢«ç»ˆæ­¢
                        if termination_requested.get(session_id, False):
                            logger.info(f"[CallAgent] ä¼šè¯ {session_id} åœ¨å‚æ•°ä¿®æ”¹é˜¶æ®µè¢«ç»ˆæ­¢")
                            yield {
                                "type": "final_response",
                                "content": "æ‰§è¡Œå·²ç»ˆæ­¢",
                                "is_final": True
                            }
                            # æ¸…ç†çŠ¶æ€
                            termination_requested[session_id] = False
                            if session_id in pending_events:
                                pending_events[session_id] = None
                            break

                        # ä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°
                        if session_id in modified_args_store:
                            call.args = modified_args_store[session_id]

                        # æ¸…ç†çŠ¶æ€
                        unmodified_schema_store[session_id] = ""

                continue

        # å¤„ç†æœ€ç»ˆå“åº”
        if event.is_final_response():
            if event.content and event.content.parts:
                yield {
                    "type": "final_response",
                    "content": event.content.parts[0].text,
                    "is_final": True
                }
            break
        else:
            if event.content and event.content.parts:
                yield {
                    "type": "streaming_response",
                    "content": event.content.parts[0].text,
                    "is_final": False
                }


# APIç«¯ç‚¹
@app.post("/api/login")
async def login(request: LoginRequest):
    """å¤„ç†ç™»å½•é€»è¾‘"""
    session_id = request.session_id
    logger.info(f"æ”¶åˆ°ç™»å½•è¯·æ±‚ï¼Œä¼šè¯ID: {session_id}")

    if not session_id:
        raise HTTPException(status_code=400, detail="è¯·å¡«å†™ä¼šè¯ID")
    elif len(session_id) != 32:
        raise HTTPException(status_code=400, detail="ä¼šè¯IDéœ€è¦ä¸ºé•¿åº¦ä¸º32çš„ä»»æ„å­—ç¬¦")

    # åˆ›å»ºæˆ–è·å–agent
    if session_id not in active_agents:
        try:
            agent = create_llm_agent(
                session_id=session_id,
                mcp_tools_url=mcp_server_url,
                agent_info=agent_info,
                model_config=model_config
            )
            active_agents[session_id] = agent
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"åˆ›å»ºAgentå¤±è´¥: {str(e)}")

    logger.info(f"ç™»å½•æˆåŠŸï¼Œä¼šè¯ID: {session_id}")
    return {"message": "ç™»å½•æˆåŠŸ", "session_id": session_id}


@app.post("/api/chat")
async def chat_with_agent(message: ChatMessage):
    """ä¸agentå¯¹è¯çš„HTTPç«¯ç‚¹ (éæµå¼)"""
    session_id = message.session_id
    user_message = message.message

    if session_id not in active_agents:
        raise HTTPException(status_code=404, detail="Agentæœªæ‰¾åˆ°ï¼Œè¯·é‡æ–°ç™»å½•")

    agent = active_agents[session_id]
    session = await session_service.create_session(
        app_name=agent_info["name"],
        user_id=session_id[:4],
        session_id=session_id
    )

    runner = Runner(
        agent=agent,
        app_name=agent_info["name"],
        session_service=session_service
    )

    full_response = ""
    async for response in call_agent_async(user_message, runner, session_id[:4], session_id):
        full_response += response.get("content", "")

    chat_id = message.chat_id
    
    # ç¡®ä¿ chat_id å­˜åœ¨
    if not chat_id:
        chat_id = session_id
        print(f"WARNING: No chat_id provided in HTTP request, falling back to user_id: {chat_id}")
        logger.warning(f"No chat_id provided in HTTP request, falling back to user_id: {chat_id}")

    # æ‡’åŠ è½½èŠå¤©å†å²
    if chat_id not in history_pool:
        history_pool[chat_id] = load_session_history(session_id, chat_id, work_path)

    # æ›´æ–°èŠå¤©å†å²
    history = history_pool[chat_id]
    history.append([user_message, full_response])
    
    # åŒæ­¥æ›´æ–° sessions.json
    update_session_history(session_id, chat_id, history, work_path)

    return {"response": full_response, "is_final": True}


@app.websocket("/ws/chat/{session_id}")
async def websocket_chat(websocket: WebSocket, session_id: str):
    """WebSocketèŠå¤©ç«¯ç‚¹ï¼Œæ”¯æŒæµå¼å“åº”"""
    await manager.connect(websocket, session_id)

    # è·å– cookies ç”¨äºå…‰å­æ”¶è´¹
    cookies = None
    try:
        # FastAPI WebSocket ä¸ç›´æ¥æä¾› cookies å±æ€§ï¼Œéœ€è¦ä»è¯·æ±‚ä¸­è·å–
        cookies = dict(websocket._cookies) if hasattr(websocket, '_cookies') else {}
        logger.info(f"WebSocket connection cookies: {list(cookies.keys())}")
    except Exception as e:
        logger.warning(f"Failed to get WebSocket cookies: {e}")
        cookies = {}

    try:
        if session_id not in active_agents:
            await websocket.send_text(json.dumps({
                "type": "error",
                "message": "Agentæœªæ‰¾åˆ°ï¼Œè¯·é‡æ–°ç™»å½•"
            }))
            return

        agent = active_agents[session_id]
        
        try:
            session = await session_service.create_session(
                app_name=agent_info["name"],
                user_id=session_id[:4],
                session_id=session_id
            )
        except Exception as e:
            logger.error(f"Failed to create session: {e}")
            raise

        runner = Runner(
            agent=agent,
            app_name=agent_info["name"],
            session_service=session_service
        )

        while True:
            data = await websocket.receive_text()
            message_data = json.loads(data)
            user_message = message_data.get("message", "")
            chat_id = message_data.get("chat_id")

            if not user_message.strip():
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "message": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"
                }))
                continue

            response_text = ""
            usage_metadata = None
            try:
                async for response in call_agent_async(user_message, runner, session_id[:4], session_id):
                    if response["type"] in ["streaming_response", "final_response"]:
                        response_text += (response.get("content") or "")

                        # Check for usage metadata
                        if "usage" in response:
                             # Send usage info to frontend
                             await websocket.send_text(json.dumps({
                                 "type": "usage_update",
                                 "usage": response["usage"]
                             }))
                             # Store usage metadata for photon charging
                             usage_metadata = response["usage"]

                        await websocket.send_text(json.dumps(response))
            except Exception as e:
                logger.error(f"Error during agent execution: {e}")
                import traceback
                traceback.print_exc()
                
                # Try to extract more info if it's an ExceptionGroup (Python 3.11+)
                if hasattr(e, 'exceptions'):
                    for i, exc in enumerate(e.exceptions):
                        logger.error(f"Sub-exception {i+1}: {exc}")
                        
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "message": f"Agent execution error: {str(e)}. Please try again."
                }))
                continue

            # æ‰§è¡Œå…‰å­æ”¶è´¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            charge_result = None
            if CHARGING_ENABLED and usage_metadata:
                try:
                    photon_service = get_photon_service()
                    if photon_service:
                        input_tokens = usage_metadata.get("promptTokenCount", 0) or usage_metadata.get("prompt_tokens", 0)
                        output_tokens = usage_metadata.get("candidatesTokenCount", 0) or usage_metadata.get("candidates_tokens", 0)

                        logger.info(f"Processing photon charge - Input: {input_tokens}, Output: {output_tokens}")

                        charge_result = await photon_service.charge_photon(
                            input_tokens=input_tokens,
                            output_tokens=output_tokens,
                            tool_calls=0,
                            websocket_cookies=cookies
                        )

                        # å‘é€æ”¶è´¹ç»“æœåˆ°å‰ç«¯
                        await websocket.send_text(json.dumps({
                            "type": "charge_result",
                            "charge_result": {
                                "success": charge_result.success,
                                "code": charge_result.code,
                                "message": charge_result.message,
                                "biz_no": str(charge_result.biz_no) if charge_result.biz_no else None,
                                "photon_amount": charge_result.photon_amount,
                                "rmb_amount": charge_result.rmb_amount
                            }
                        }))

                        if charge_result.success:
                            logger.info(f"Photon charge successful: {charge_result.message}")
                        else:
                            logger.warning(f"Photon charge failed: {charge_result.message}")
                except Exception as charge_error:
                    logger.error(f"Error during photon charging: {charge_error}")
                    await websocket.send_text(json.dumps({
                        "type": "charge_result",
                        "charge_result": {
                            "success": False,
                            "code": -1,
                            "message": f"æ”¶è´¹å¼‚å¸¸: {str(charge_error)}",
                            "photon_amount": 0,
                            "rmb_amount": 0.0
                        }
                    }))

            # ç¡®ä¿ chat_id å­˜åœ¨
            if not chat_id:
                # å¦‚æœæ²¡æœ‰ chat_idï¼Œå°è¯•ä½¿ç”¨ session_id (å…¼å®¹æ—§é€»è¾‘ï¼Œä½†ä¸æ¨è)
                chat_id = session_id
                logger.warning(f"No chat_id provided, falling back to user_id: {chat_id}")

            # æ‡’åŠ è½½èŠå¤©å†å² (ä» sessions.json)
            if chat_id not in history_pool:
                history_pool[chat_id] = load_session_history(session_id, chat_id, work_path)

            # æ›´æ–°èŠå¤©å†å²
            history = history_pool[chat_id]
            history.append([user_message, response_text])
            
            # åŒæ­¥æ›´æ–° sessions.json (è¿™æ˜¯å”¯ä¸€çš„æŒä¹…åŒ–å­˜å‚¨)
            update_session_history(session_id, chat_id, history, work_path)

    except WebSocketDisconnect:
        manager.disconnect(session_id)
    except Exception as e:
        logger.critical(f"CRITICAL ERROR in websocket_chat: {e}")
        import traceback
        traceback.print_exc()
        try:
            await websocket.close(code=1011) # Internal Error
        except:
            pass
        manager.disconnect(session_id)


@app.post("/api/modify-params")
async def modify_parameters(request: ModifyParamsRequest):
    """å¤„ç†å‚æ•°ä¿®æ”¹è¯·æ±‚"""
    session_id = request.session_id
    modified_schema = request.modified_schema

    logger.info("=" * 80)
    logger.info(f"[ModifyParams] æ”¶åˆ°å‚æ•°ä¿®æ”¹è¯·æ±‚")
    logger.info(f"[ModifyParams] Session ID: {session_id}")
    logger.info(f"[ModifyParams] å·¥å…·åç§°: {modified_schema.get('name', 'unknown')}")
    logger.info(f"[ModifyParams] æ‰§è¡Œæ¨¡å¼: {request.execution_mode}")
    logger.info(f"[ModifyParams] é€‰ä¸­çš„æœºå™¨ID: {request.selected_machine_id}")
    logger.info(f"[ModifyParams] ä¿®æ”¹å‰çš„Schema: {json.dumps(modified_schema, ensure_ascii=False, indent=2)}")
    logger.info("=" * 80)

    # æ„å»ºå·¥ä½œç›®å½•è·¯å¾„ï¼š{work_path}/{session_id}/filesï¼ˆç¡®ä¿æ˜¯ç»å¯¹è·¯å¾„ï¼‰
    session_files_dir = os.path.abspath(os.path.join(work_path, session_id, "files"))

    # è‡ªåŠ¨ç”Ÿæˆ Executor å’Œ Storage å‚æ•°
    modified_schema = generate_executor_and_storage(
        execution_mode=request.execution_mode,
        remote_machine=request.remote_machine,
        tool_schema=modified_schema
    )

    logger.info("=" * 80)
    logger.info(f"[ModifyParams] ç”Ÿæˆ Executor å’Œ Storage åçš„Schema: {json.dumps(modified_schema, ensure_ascii=False, indent=2)}")
    logger.info("=" * 80)

    # æå–ä¿®æ”¹åçš„å‚æ•°
    modified_args = extract_arguments_from_schema(modified_schema)

    # å¤„ç†è·¯å¾„å‚æ•°ï¼šç¡®ä¿æ‰€æœ‰è·¯å¾„éƒ½æ˜¯ç»å¯¹è·¯å¾„
    properties = modified_schema.get('input_schema', {}).get('properties', {})
    for param_name, param_info in properties.items():
        if param_name.endswith('_path') and param_name in modified_args:
            user_input = modified_args[param_name]
            if user_input and isinstance(user_input, str):
                # ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
                if os.path.isabs(user_input):
                    # å·²ç»æ˜¯ç»å¯¹è·¯å¾„ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if os.path.exists(user_input):
                        logger.info(f"[ModifyParams] è·¯å¾„å‚æ•° {param_name}: ä¿æŒç»å¯¹è·¯å¾„ {user_input}")
                    else:
                        logger.warning(f"[ModifyParams] è·¯å¾„å‚æ•° {param_name}: ç»å¯¹è·¯å¾„ä¸å­˜åœ¨ {user_input}")
                else:
                    # ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•åœ¨ session_files_dir ä¸­æŸ¥æ‰¾
                    possible_path = os.path.join(session_files_dir, user_input)
                    if os.path.exists(possible_path):
                        modified_args[param_name] = possible_path
                        logger.info(f"[ModifyParams] è·¯å¾„å‚æ•° {param_name}: ç›¸å¯¹è·¯å¾„è½¬ç»å¯¹è·¯å¾„ {user_input} -> {possible_path}")
                    else:
                        # å°è¯•ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
                        cwd_path = os.path.abspath(user_input)
                        if os.path.exists(cwd_path):
                            modified_args[param_name] = cwd_path
                            logger.info(f"[ModifyParams] è·¯å¾„å‚æ•° {param_name}: ä½¿ç”¨å½“å‰å·¥ä½œç›®å½• {user_input} -> {cwd_path}")
                        else:
                            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½†ä»ç„¶æ„å»ºé¢„æœŸçš„ç»å¯¹è·¯å¾„
                            modified_args[param_name] = possible_path
                            logger.warning(f"[ModifyParams] è·¯å¾„å‚æ•° {param_name}: æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é¢„æœŸè·¯å¾„ {user_input} -> {possible_path}")

    logger.info(f"[ModifyParams] æå–åçš„å‚æ•°: {modified_args}")
    logger.info(f"[ModifyParams] Executor å‚æ•°: {modified_args.get('executor')}")
    logger.info(f"[ModifyParams] Storage å‚æ•°: {modified_args.get('storage')}")

    modified_args_store[session_id] = modified_args
    modified_schema_store[session_id] = modified_schema

    # æ¢å¤agentæ‰§è¡Œ
    if session_id in pending_events:
        logger.info(f"[ModifyParams] è§¦å‘äº‹ä»¶ï¼Œæ¢å¤ agent æ‰§è¡Œ")
        pending_events[session_id].set()
    else:
        logger.warning(f"[ModifyParams] Session {session_id} æ²¡æœ‰å¾…å¤„ç†çš„äº‹ä»¶")

    return {"message": "å‚æ•°å·²æ›´æ–°", "modified_args": modified_args}


@app.post("/api/terminate-execution")
async def terminate_execution(request: TerminateExecutionRequest):
    """ç»ˆæ­¢æ­£åœ¨æ‰§è¡Œçš„ agent ä»»åŠ¡"""
    session_id = request.session_id

    logger.info("=" * 80)
    logger.info(f"[TerminateExecution] æ”¶åˆ°ç»ˆæ­¢æ‰§è¡Œè¯·æ±‚")
    logger.info(f"[TerminateExecution] Session ID: {session_id}")
    logger.info("=" * 80)

    # æ ‡è®°ä¼šè¯éœ€è¦ç»ˆæ­¢
    termination_requested[session_id] = True

    # è§¦å‘å–æ¶ˆäº‹ä»¶
    if session_id in pending_events:
        # è®¾ç½®ç»ˆæ­¢äº‹ä»¶ï¼Œä½¿ wait ç«‹å³è¿”å›
        if session_id not in cancel_execution_events:
            cancel_execution_events[session_id] = asyncio.Event()
        cancel_execution_events[session_id].set()

        # åŒæ—¶è§¦å‘ pending_event ä½¿å…¶è¿”å›
        pending_events[session_id].set()

        logger.info(f"[TerminateExecution] å·²è§¦å‘ä¼šè¯ {session_id} çš„ç»ˆæ­¢ä¿¡å·")
        return {"message": "ç»ˆæ­¢è¯·æ±‚å·²å‘é€", "status": "terminating"}
    else:
        logger.warning(f"[TerminateExecution] Session {session_id} æ²¡æœ‰å¾…å¤„ç†çš„äº‹ä»¶")
        return {"message": "æ²¡æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡", "status": "no_active_task"}


@app.get("/api/files/{session_id}")
async def list_files(session_id: str):
    """è·å–ä¼šè¯æ–‡ä»¶åˆ—è¡¨"""
    session_dir = os.path.join(work_path, session_id, "files")
    logger.info(f"Listing files from: {session_dir}")
    os.makedirs(session_dir, exist_ok=True)

    files = []
    if os.path.exists(session_dir):
        for filename in os.listdir(session_dir):
            file_path = os.path.join(session_dir, filename)
            if os.path.isfile(file_path):
                stats = os.stat(file_path)
                files.append({
                    "name": filename,
                    "path": file_path,
                    "size": stats.st_size,
                    "updated_at": stats.st_mtime
                })
    logger.info(f"Found {len(files)} files")
    return {"files": sorted(files, key=lambda x: x["name"])}


@app.post("/api/upload/{session_id}")
async def upload_file(session_id: str, files: List[UploadFile] = File(...)):
    """ä¸Šä¼ æ–‡ä»¶åˆ°ä¼šè¯ç›®å½•"""
    session_dir = os.path.join(work_path, session_id, "files")
    os.makedirs(session_dir, exist_ok=True)

    uploaded_files = []
    for file in files:
        file_path = os.path.join(session_dir, file.filename)

        # æ£€æŸ¥æ–‡ä»¶å¤§å° (10MBé™åˆ¶)
        content = await file.read()
        if len(content) > 10 * 1024 * 1024:
            continue

        with open(file_path, "wb") as f:
            f.write(content)

        uploaded_files.append({
            "name": file.filename,
            "path": file_path,
            "size": len(content)
        })

    return {"uploaded_files": uploaded_files}


@app.get("/api/download/{session_id}/{filename:path}")
async def download_file(session_id: str, filename: str):
    """ä¸‹è½½æ–‡ä»¶ (æ”¯æŒå­ç›®å½•å’Œå¯é€‰çš„ files/ å‰ç¼€)"""
    # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœè¯·æ±‚è·¯å¾„åŒ…å« files/ å‰ç¼€ï¼ˆä¾‹å¦‚å‰ç«¯æ ¹æ®æ–‡ä»¶ç³»ç»Ÿè·¯å¾„æ‹¼æ¥ï¼‰ï¼Œåˆ™ç§»é™¤
    # è¿™æ · /api/download/xxx/band.png å’Œ /api/download/xxx/files/band.png éƒ½èƒ½å·¥ä½œ
    clean_filename = filename
    if clean_filename.startswith("files/"):
        clean_filename = clean_filename[6:]
    elif clean_filename.startswith("/files/"):
        clean_filename = clean_filename[7:]
    
    file_path = os.path.join(work_path, session_id, "files", clean_filename)

    # é˜²æ­¢è·¯å¾„éå†æ”»å‡»
    # ... (Normally we should check commonprefix, but assuming session_id isolation is enough for now for internal tool)

    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    return FileResponse(file_path, filename=os.path.basename(clean_filename))

@app.delete("/api/files/{session_id}/{filename:path}")
async def delete_file(session_id: str, filename: str):
    """åˆ é™¤æ–‡ä»¶"""
    # åŒæ ·çš„é€»è¾‘
    clean_filename = filename
    if clean_filename.startswith("files/"):
        clean_filename = clean_filename[6:]
        
    file_path = os.path.join(work_path, session_id, "files", clean_filename)

    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    try:
        os.remove(file_path)
        return {"message": "æ–‡ä»¶å·²åˆ é™¤", "filename": clean_filename}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")


@app.get("/api/sessions/{session_id}/history")
async def get_chat_history(session_id: str):
    """è·å–èŠå¤©å†å² (Legacy)"""
    history = history_pool.get(session_id, load_chat_history(session_id, work_path))
    return {"history": history}


@app.post("/api/sessions/{session_id}/clear")
async def clear_chat_history(session_id: str):
    """æ¸…ç©ºèŠå¤©å†å² (Legacy)"""
    history_pool[session_id] = []
    save_chat_history(session_id, [], work_path)
    return {"message": "èŠå¤©å†å²å·²æ¸…ç©º"}


class SaveSessionsRequest(BaseModel):
    sessions: List[Dict[str, Any]]


@app.get("/api/user/{user_id}/sessions")
async def get_user_sessions(user_id: str):
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰èŠå¤©ä¼šè¯"""
    user_dir = os.path.join(work_path, user_id)
    sessions_file = os.path.join(user_dir, "sessions.json")
    logger.info(f"Loading sessions for {user_id} from {sessions_file}")
    
    if os.path.exists(sessions_file):
        try:
            with open(sessions_file, 'r', encoding='utf-8') as f:
                sessions = json.load(f)
            
            # è½¬æ¢å†å²è®°å½•æ ¼å¼ä»¥é€‚é…å‰ç«¯: [[q, a], ...] -> [{role: user, content: q}, {role: assistant, content: a}, ...]
            for session in sessions:
                raw_history = session.get("history", [])
                formatted_history = []
                for item in raw_history:
                    if isinstance(item, list) and len(item) >= 2:
                        formatted_history.append({"role": "user", "content": item[0]})
                        formatted_history.append({"role": "assistant", "content": item[1]})
                session["history"] = formatted_history
                # Update message count to reflect total messages (user + assistant)
                session["message_count"] = len(formatted_history)
            
            logger.info(f"Loaded {len(sessions)} sessions")
            return {"sessions": sessions}
        except Exception as e:
            logger.error(f"Error loading sessions: {e}")
            return {"sessions": []}
    logger.warning("Sessions file not found")
    return {"sessions": []}


def load_session_history(user_id: str, chat_id: str, work_path: str) -> List[List[str]]:
    """ä» sessions.json åŠ è½½ç‰¹å®šä¼šè¯çš„å†å²è®°å½•"""
    user_dir = os.path.join(work_path, user_id)
    sessions_file = os.path.join(user_dir, "sessions.json")
    
    if not os.path.exists(sessions_file):
        return []

    try:
        with open(sessions_file, 'r', encoding='utf-8') as f:
            sessions = json.load(f)
        
        for session in sessions:
            if session.get("chat_id") == chat_id:
                return session.get("history", [])
    except Exception as e:
        logger.error(f"Error loading session history: {e}")
    
    return []


def update_session_history(user_id: str, session_id: str, history: List[List[str]], work_path: str):
    """æ›´æ–°ç”¨æˆ·ä¼šè¯åˆ—è¡¨ä¸­çš„å†å²è®°å½•"""
    logger.debug(f"Updating session history for User: {user_id}, Chat: {session_id}, History Len: {len(history)}")
    user_dir = os.path.join(work_path, user_id)
    sessions_file = os.path.join(user_dir, "sessions.json")
    
    if not os.path.exists(sessions_file):
        logger.warning(f"Sessions file not found: {sessions_file}")
        return

    try:
        with open(sessions_file, 'r', encoding='utf-8') as f:
            sessions = json.load(f)
        
        updated = False
        for session in sessions:
            # logger.debug(f"Checking session {session.get('chat_id')} against {session_id}")
            if session.get("chat_id") == session_id:
                session["history"] = history
                session["last_active"] = datetime.now().isoformat()
                session["message_count"] = len(history)
                updated = True
                logger.debug(f"Found and updated session {session_id}")
                break
        
        if updated:
            with open(sessions_file, 'w', encoding='utf-8') as f:
                json.dump(sessions, f, ensure_ascii=False, indent=2)
            logger.debug("Successfully saved sessions.json")
        else:
            logger.warning(f"Chat ID {session_id} not found in sessions.json")
            
    except Exception as e:
        logger.error(f"Failed to update session history in sessions.json: {e}")


@app.post("/api/user/{user_id}/sessions")
async def save_user_sessions(user_id: str, request: SaveSessionsRequest):
    """ä¿å­˜ç”¨æˆ·çš„æ‰€æœ‰èŠå¤©ä¼šè¯"""
    user_dir = os.path.join(work_path, user_id)
    os.makedirs(user_dir, exist_ok=True)
    sessions_file = os.path.join(user_dir, "sessions.json")
    logger.info(f"Saving {len(request.sessions)} sessions for {user_id} to {sessions_file}")
    
    try:
        with open(sessions_file, 'w', encoding='utf-8') as f:
            json.dump(request.sessions, f, ensure_ascii=False, indent=2)
        return {"message": "Sessions saved successfully"}
    except Exception as e:
        logger.error(f"Failed to save sessions: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to save sessions: {str(e)}")


@app.get("/api/schema/{session_id}")
async def get_current_schema(session_id: str):
    """è·å–å½“å‰éœ€è¦ä¿®æ”¹çš„å‚æ•°schema"""
    schema = unmodified_schema_store.get(session_id, {})
    return {"schema": schema}


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "ok", "message": "Backend is running"}

@app.get("/api/config")
async def get_config():
    """è·å–åº”ç”¨é…ç½®ä¿¡æ¯"""
    logger.info("æ”¶åˆ°é…ç½®è¯·æ±‚")
    config = {
        "agent_info": agent_info,
        "mcp_server_url": mcp_server_url,
        "target_tools": target_tools
    }
    logger.debug(f"è¿”å›é…ç½®ä¿¡æ¯: {config}")
    return config


# åˆå§‹åŒ–å‡½æ•°
def initialize_server(
    agent_info_dict: Dict[str, Any],
    model_config_dict: Dict[str, Any],
    mcp_url: str,
    work_dir: str = "/tmp",
    tools_modify: List[str] = None
):
    """åˆå§‹åŒ–æœåŠ¡å™¨é…ç½®"""
    global agent_info, model_config, mcp_server_url, work_path, target_tools, tools_info

    agent_info = agent_info_dict
    model_config = model_config_dict
    mcp_server_url = mcp_url
    work_path = work_dir
    target_tools = tools_modify or []

    # åŠ è½½MCPå·¥å…·ä¿¡æ¯
    try:
        tools_info = asyncio.run(get_mcp_server_tools(mcp_server_url))
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(tools_info)} ä¸ªMCPå·¥å…·")
    except Exception as e:
        logger.error(f"âš ï¸  åŠ è½½MCPå·¥å…·å¤±è´¥: {e}")
        tools_info = []

    # é…ç½®é™æ€æ–‡ä»¶æœåŠ¡ (å¦‚æœåœ¨ç”Ÿäº§ç¯å¢ƒä¸”å­˜åœ¨dist)
    configure_static_serving()


def configure_static_serving():
    """é…ç½®å‰ç«¯é™æ€æ–‡ä»¶æœåŠ¡"""
    from fastapi.staticfiles import StaticFiles
    from fastapi.responses import FileResponse

    # å°è¯•æ‰¾åˆ°distç›®å½•
    # app.py path: .../dptb-pilot/dptb_pilot/server/app.py
    # web_ui path: .../dptb-pilot/web_ui
    server_dir = os.path.dirname(__file__)
    pilot_pkg_dir = os.path.dirname(server_dir)
    project_root = os.path.dirname(pilot_pkg_dir)

    possible_paths = [
        os.path.join(project_root, "web_ui", "dist"), # Best for packaged/repo run
        os.path.join(os.getcwd(), "web_ui", "dist"),  # Best for local dev in root
    ]
    
    dist_path = None
    for path in possible_paths:
        if os.path.exists(path) and os.path.exists(os.path.join(path, "index.html")):
            dist_path = path
            break
            
    if dist_path:
        logger.info(f"ğŸ¨ å¯ç”¨é™æ€æ–‡ä»¶æ‰˜ç®¡: {dist_path}")
        
        # 1. Mount assets
        assets_path = os.path.join(dist_path, "assets")
        if os.path.exists(assets_path):
            app.mount("/assets", StaticFiles(directory=assets_path), name="assets")
            
        # 2. Mount other static folders if needed (e.g. vite creates assets, maybe others?)
        # For safety, we can mount root, but it might shadow API.
        
        # 3. Catch-all route for SPA (Must be last)
        @app.get("/{full_path:path}")
        async def serve_spa(full_path: str):
            # APIå’ŒWebSocketå·²ç»è¢«å‰é¢çš„è·¯ç”±æ•è·ï¼Œè¿™é‡Œåªå¤„ç†å‰ç«¯è·¯ç”±
            if full_path.startswith("api/") or full_path.startswith("ws/"):
                raise HTTPException(status_code=404, detail="Not Found")
            
            # Check if file exists in dist (e.g. favicon.ico)
            file_path = os.path.join(dist_path, full_path)
            if os.path.isfile(file_path):
                 return FileResponse(file_path)
                 
            # å¦åˆ™è¿”å›index.html (SPAè·¯ç”±)
            return FileResponse(os.path.join(dist_path, "index.html"))
            
        logger.info("âœ… å‰ç«¯é™æ€æœåŠ¡å·²é…ç½® (SPA Mode)")
    else:
        logger.info("â„¹ï¸ æœªå‘ç°å‰ç«¯ç¼–è¯‘äº§ç‰©ï¼Œè·³è¿‡é™æ€æœåŠ¡é…ç½® (è¯·ä½¿ç”¨ npm run dev)")


def run_server(host: str = "0.0.0.0", port: int = 8000):
    """è¿è¡ŒæœåŠ¡å™¨"""
    uvicorn.run(app, host=host, port=port)


if __name__ == "__main__":
    run_server()